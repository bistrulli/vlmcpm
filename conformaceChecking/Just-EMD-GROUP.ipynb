{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esa53mBk7HwV",
    "outputId": "59bad562-01e1-4bfb-db59-9c4a21a550b4"
   },
   "outputs": [],
   "source": [
    "# %pip install pm4py\n",
    "# %pip install pyemd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import multiprocessing as mp\n",
    "import argparse\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import xml.parsers.expat\n",
    "import warnings\n",
    "import random\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "from pm4py.objects.petri_net.importer import importer as pnml_importer\n",
    "from pm4py.algo.simulation.playout.petri_net import algorithm as simulator\n",
    "from pm4py.statistics.variants.log import get as variants_module\n",
    "from pm4py.algo.evaluation.earth_mover_distance import algorithm as emd_evaluator\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='pm4py.utils')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='pm4py.objects.stochastic_petri')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='pm4py.algo.simulation.montecarlo')\n",
    "\n",
    "#os.chdir(r'/users/sima/Desktop/stochastic/EMD-GROUP')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E83ZG7pF67Dy"
   },
   "source": [
    "# **The main estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylNwT4KTVlKs"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "\n",
    "\n",
    "train_logfile =r'bubble2_train.xes'\n",
    "log = pm4py.read_xes(train_logfile)\n",
    "\n",
    "\n",
    "log['case:concept:name'] = log['case:concept:name'].astype(str)\n",
    "log['concept:name']      = log['concept:name'].astype(str)\n",
    "# log['time:timestamp']    = pd.to_datetime(log['time:timestamp'], utc=True)\n",
    "log['time:timestamp'] = pd.to_datetime(log['time:timestamp'], format=\"%Y-%m-%dT%H:%M:%S\", utc=True)\n",
    "\n",
    "test_logfile_path1 = r'bubble2_test.csv'\n",
    "full_log1 =  pd.read_csv(test_logfile_path1)\n",
    "\n",
    "log = pm4py.convert_to_event_log(log)\n",
    "language_model = variants_module.get_language(log)\n",
    "# xes_exporter.apply(language_model, 'language_model_of_train.xes')\n",
    "print('language of model is produced')\n",
    "def perform_analysis(num_groups,language_model, test_log,seed=None,limit=1000):\n",
    "    test_log = test_log.copy()\n",
    "\n",
    "    test_log['case:concept:name'] = test_log['case:concept:name'].astype(str)\n",
    "    test_log['concept:name']      = test_log['concept:name'].astype(str)\n",
    "    # test_log['time:timestamp']    = pd.to_datetime(test_log['time:timestamp'], utc=True)\n",
    "    #format=\"%Y-%m-%d %H:%M:%S\"\n",
    "    test_log['time:timestamp'] = pd.to_datetime(test_log['time:timestamp'], utc=True,format=\"ISO8601\")\n",
    "\n",
    "    # Get unique case IDs and divide them into num_groups\n",
    "    case_ids = test_log['case:concept:name'].unique()\n",
    "    # Shuffle case_ids with a seed\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.shuffle(case_ids)\n",
    "\n",
    "\n",
    "    grouped_case_ids = np.array_split(case_ids, num_groups)\n",
    "\n",
    "    emd_results = []\n",
    "    \n",
    "    for idx,group_case_ids in enumerate(tqdm(grouped_case_ids)):\n",
    "        \n",
    "        group_df = test_log[test_log['case:concept:name'].isin(group_case_ids)]\n",
    "\n",
    "        if not group_df.empty:\n",
    "            traditional_log = pm4py.convert_to_event_log(group_df)\n",
    "            case_language = variants_module.get_language(traditional_log)\n",
    "            emd_value = emd_evaluator.apply(language_model, case_language)\n",
    "            emd_results.append(emd_value)\n",
    "        if(idx>=limit):\n",
    "            break\n",
    "\n",
    "    # Convert the list of results to a DataFrame\n",
    "    emd_df = pd.DataFrame({'EMD Value': emd_results})\n",
    "\n",
    "    return emd_df\n",
    "\n",
    "\n",
    "\n",
    "def main(language_model, full_log1, num_groups):\n",
    "    emd_estimation_start_time_group = time.time()\n",
    "    emd_df = perform_analysis(num_groups, language_model, full_log1)\n",
    "    average_emd = emd_df['EMD Value'].mean()\n",
    "\n",
    "    emd_estimation_time_group = time.time() - emd_estimation_start_time_group\n",
    "    return emd_df,average_emd, emd_estimation_time_group\n",
    "\n",
    "# nruns = [5000]\n",
    "group_counts = [1, 2 ,10 ,50 ,200,500, 1000,2000,5000 ,10000]\n",
    "#group_counts = [1, 2 ,10 ,50 ,200,500, 1000]\n",
    "#group_counts = [10000]\n",
    "\n",
    "\n",
    "seed = 117\n",
    "\n",
    "# Directory path for the tracking DataFrame\n",
    "tracking_df_directory = 'EMD-GROUP-BUBBLE2'\n",
    "# Check if directory exists, and create it if it doesn't\n",
    "if not os.path.exists(tracking_df_directory):\n",
    "    os.makedirs(tracking_df_directory)\n",
    "\n",
    "tracking_df_group = pd.DataFrame(columns=['Num Groups', 'EMD Estimation Time', 'EMD CSV File'])\n",
    "tracking_df_group = pd.DataFrame(columns=['Num Groups', 'Average EMD', 'EMD Estimation Time', 'EMD CSV File'])\n",
    "\n",
    "\n",
    "for num_groups in group_counts:\n",
    "    print(f'EMD analysis for num_groups= {num_groups} is started')\n",
    "\n",
    "    emd_df,average_emd , emd_estimation_time_group= main(language_model, full_log1, num_groups)\n",
    "    print('Emd evaluated')\n",
    "    csv_file_path = f'{tracking_df_directory}/EMD_SOLO_nGroup{num_groups}.csv'\n",
    "    emd_df.to_csv(csv_file_path, index=False)\n",
    "    print(f'EMD results for num_groups= {num_groups} saved to {csv_file_path}')\n",
    "\n",
    "    new_row = {\n",
    "        'Num Groups': num_groups,\n",
    "        'Average EMD': average_emd,\n",
    "        'EMD Estimation Time': emd_estimation_time_group,\n",
    "        'EMD CSV File': csv_file_path,\n",
    "    }\n",
    "\n",
    "    tracking_csv_file_path = os.path.join(tracking_df_directory, \"EMD_SOLO_tracking_groups.csv\")\n",
    "\n",
    "    tracking_df_group = pd.concat([tracking_df_group, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    tracking_df_group.to_csv(tracking_csv_file_path, index=False)\n",
    "    print(f'Tracking DataFrame updated for num_groups= {num_groups}')\n",
    "\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "print('Analysis finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E83ZG7pF67Dy"
   },
   "source": [
    "# **Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = [1, 2 ,10 ,50 ,200,500, 1000,2000,5000 ,10000]\n",
    "#group_counts = [1, 2 ,10 ,50 ,200,500]\n",
    "resdir=\"EMD-GROUP\"\n",
    "res=[]\n",
    "res_solo=pd.read_csv(f\"{resdir}/EMD_SOLO_tracking_groups.csv\")\n",
    "runtime=round(res_solo[\"EMD Estimation Time\"],2)\n",
    "thresh_ar=[0.001,0.27,0.33,0.55] #Simple\n",
    "#thresh_ar=[0.001,0.33,0.38,0.55] #Hard\n",
    "for thresh in thresh_ar:\n",
    "    for gc in reversed(group_counts):\n",
    "        idx=group_counts.index(gc)\n",
    "        df_res=pd.read_csv(f\"{resdir}/EMD_SOLO_nGroup{gc}.csv\")\n",
    "        df_res_sel=pd.read_csv(f\"EMD-GROUP-SEL/EMD_SOLO_nGroup{gc}.csv\")\n",
    "        tp=round(df_res[df_res[\"EMD Value\"]<=thresh].shape[0]*100/df_res.shape[0],2)\n",
    "        fn=round(100-tp,2)\n",
    "        fp=round(df_res_sel[df_res_sel[\"EMD Value\"]<=thresh].shape[0]*100/df_res_sel.shape[0],2)\n",
    "        tn=round(df_res_sel[df_res_sel[\"EMD Value\"]>thresh].shape[0]*100/df_res_sel.shape[0],2)\n",
    "        res.append([gc,df_res[\"EMD Value\"].mean(),df_res_sel[\"EMD Value\"].mean(),runtime[idx],\n",
    "                    tp,fn,fp,tn,round(thresh,3)])\n",
    "        #print(\"gc=\",gc,\"tp=\",tp,\"fn=\",fn,\"fp=\",fp,\"tn=\",tn,round(thresh,4))\n",
    "        #print(\"gc=\",gc,\"tp=\",tp,\"fn=\",fn,round(thresh,4))\n",
    "        #print(\"%d & %.4f & %.2f & 0 & %.2f&-&-&-&-\\\\\\\\\"%(10000//gc,round(thresh,4),runtime[idx],fn))\n",
    "df = pd.DataFrame(data=np.array(res), columns=[\"GC\",\"EMD1\",\"EMD2\",\"Time\",'TP', 'FN', 'FP',\"TN\",\"TH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"GC\",\"EMD1\",\"EMD2\",\"Time\",\"TP\",\"TN\",\"TH\"]]\n",
    "result_concat=df[df[\"TH\"]==thresh_ar[0]]\n",
    "result_concat.reset_index(drop=True, inplace=True)\n",
    "for t in thresh_ar[1:]:\n",
    "    df2=df[df[\"TH\"]==t][[\"TP\",\"TN\"]]\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    result_concat = pd.concat([result_concat, df2],ignore_index=True,axis=1)\n",
    "if(len(thresh_ar)>1):\n",
    "    result_concat=result_concat.rename(columns={0: \"GC\",1:\"EMD1\",2:\"EMD2\",3:\"Time\",4:\"TP\",5:\"TN\",6:\"TH\"})\n",
    "for idx,val in enumerate(thresh_ar[1:]):\n",
    "    result_concat=result_concat.rename(columns={idx*2+7:f\"TP{idx+1}\",idx*2+8:f\"TN{idx+1}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrrrrrr}\n",
      "\\toprule\n",
      "\\midrule\n",
      "1 & 0.27 & 0.34 & 45963.07 & 0.00 & 100.00 & 63.88 & 100.00 & 93.83 & 65.66 & 99.79 & 0.00 \\\\\n",
      "2 & 0.23 & 0.32 & 23045.58 & 0.00 & 100.00 & 90.42 & 99.94 & 97.90 & 17.28 & 99.96 & 0.00 \\\\\n",
      "5 & 0.18 & 0.29 & 9219.71 & 0.00 & 100.00 & 99.15 & 97.35 & 99.95 & 0.00 & 100.00 & 0.00 \\\\\n",
      "10 & 0.14 & 0.28 & 4674.00 & 0.00 & 100.00 & 100.00 & 80.20 & 100.00 & 0.00 & 100.00 & 0.00 \\\\\n",
      "20 & 0.11 & 0.27 & 2426.64 & 0.00 & 100.00 & 100.00 & 25.80 & 100.00 & 0.00 & 100.00 & 0.00 \\\\\n",
      "50 & 0.08 & 0.25 & 1072.01 & 0.00 & 100.00 & 100.00 & 0.00 & 100.00 & 0.00 & 100.00 & 0.00 \\\\\n",
      "200 & 0.04 & 0.24 & 356.66 & 0.00 & 100.00 & 100.00 & 0.00 & 100.00 & 0.00 & 100.00 & 0.00 \\\\\n",
      "1000 & 0.02 & 0.24 & 76.58 & 0.00 & 100.00 & 100.00 & 0.00 & 100.00 & 0.00 & 100.00 & 0.00 \\\\\n",
      "5000 & 0.01 & 0.24 & 17.50 & 0.00 & 100.00 & 100.00 & 0.00 & 100.00 & 0.00 & 100.00 & 0.00 \\\\\n",
      "10000 & 0.01 & 0.24 & 10.50 & 0.00 & 100.00 & 100.00 & 0.00 & 100.00 & 0.00 & 100.00 & 0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_concat[\"GC\"]=list(map(int,10000/result_concat[\"GC\"]))\n",
    "if \"TH\" in result_concat:\n",
    "    result_concat=result_concat.drop('TH', axis=1)\n",
    "#print(result_concat)\n",
    "print(result_concat.to_latex(index=False, header=False,float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Fx0AHkZGS38q",
    "cEkiKupm1QtX"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
